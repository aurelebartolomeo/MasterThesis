{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A : $ Y_{ij} = \\alpha_0 + b_{0i} + (\\alpha_{1A}+b_{1i} )t_j + \\epsilon_{ij}$\n",
    "\n",
    "B : $ Y_{ij} = \\alpha_0 + b_{0i} + (\\alpha_{1B}+b_{1i} )t_j + \\epsilon_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_i = 1000 # number of individuals\n",
    "alpha_0 = 2 \n",
    "b_0, b_1 = multivariate_normal.rvs(mean=np.zeros(2), cov=np.array([[1, 0.5],[0.5, 1]]), size=n_i).transpose()\n",
    "alpha_1A = 2\n",
    "alpha_1B = 0.5\n",
    "t = np.arange(10)\n",
    "epsilon = norm.rvs(loc=0, scale=0.2, size=n_i*t.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_A = []\n",
    "Y_B = []\n",
    "for i in range(n_i):\n",
    "    if(i < n_i/2):\n",
    "        new_individual = alpha_0 + b_0[i] + (alpha_1A + b_1[i]) * t + epsilon[len(t)*i : len(t)*i + len(t)]\n",
    "        Y_A.append(new_individual)\n",
    "    else: \n",
    "        new_individual = alpha_0 + b_0[i] + (alpha_1B + b_1[i]) * t + epsilon[len(t)*i : len(t)*i + len(t)]\n",
    "        Y_B.append(new_individual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Y_A + Y_B\n",
    "labels = np.append(np.ones(n_i//2), np.ones(n_i//2)*0) #A:1, B:-1\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.5999 - accuracy: 0.6513\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.6800\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5624 - accuracy: 0.7138\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7138\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7212\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7412\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7663\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7800\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7850\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2284f0fc850>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "#model.add(keras.Input(shape=(10)))\n",
    "model.add(layers.SimpleRNN(32, input_shape=(10,1)))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.194"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import bernoulli\n",
    "r = bernoulli.rvs(0.2, size=1000)\n",
    "np.mean(r)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a1efdfe260f1b6b6c10900f76cd4fcadb52d179237eb221726bea769b543dfc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
